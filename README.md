# Predicting-Adolescent-Depression

.

ğŸ“Š Predicting Adolescent Depression Using Classical ML, TabPFN & Stacked Ensembles

Authors:
Sherwin Dâ€™Souza
Monil Patel
Christom Joseph
Department of Mathematics & Statistics
University of Guelph

ğŸ“Œ Project Overview

This research project presents a comprehensive benchmarking study comparing:

Classical Machine Learning Models

Transformer-based Foundation Model (TabPFN)

Stacked Ensemble Architectures

for predicting adolescent depression using behavioral, lifestyle, and psychosocial survey data.

The goal was to evaluate model performance with a primary focus on:

ğŸ”´ Maximizing Recall for the Depressed Class
(to minimize false negatives in mental health screening)

ğŸ¯ Research Objectives

This study aimed to:

Establish baseline performance across 14 classical ML models

Evaluate TabPFNâ€™s zero-shot tabular learning capabilities

Implement stacked ensemble configurations

Address class imbalance using SMOTE

Compare sensitivity-focused performance metrics

Analyze model failures on minority class prediction

ğŸ“‚ Dataset

3,000 adolescents (ages 13â€“19)

19 final predictive features after preprocessing

Binary Target:

0 â†’ No/Minimal symptoms (70%)

1 â†’ Mild/Moderate/Severe depression (30%)

Feature Groups:

Demographics

Technology Usage Patterns

Lifestyle Indicators

Psychosocial Factors

Class imbalance handled using SMOTE applied only to training data.

âš™ï¸ Preprocessing Pipeline

Removed identifiers and leakage-prone variables

Outlier clipping (Â±3Ïƒ)

Label encoding for ordinal variables

StandardScaler applied to continuous variables

Stratified 70â€“30 train-test split

SMOTE balancing (training set only)

Final Training Set:

2,940 samples Ã— 19 features

ğŸ¤– Models Evaluated
Classical Models

Logistic Regression (Base & Tuned)

Forward / Backward Stepwise Regression

Decision Trees (Entropy & Gini)

Random Forest

Gradient Boosting

XGBoost

LightGBM

CatBoost

Multi-Layer Perceptron

Foundation Model

TabPFN (Transformer-based, Zero-Shot)

Stacked Ensembles

(LogReg + DT + RF) â†’ Logistic Meta-Learner

(RF + XGBoost) â†’ Logistic Meta-Learner

ğŸ“Š Evaluation Metrics

Primary Metric:

Recall (Depressed Class)

Secondary Metrics:

F1-Score

Accuracy

Precision

AUC (TabPFN)

ğŸ† Key Results
Model	Recall	F1	Accuracy
Tuned Logistic Regression	0.49	0.38	0.52
TabPFN	0.46	0.39	0.57
Stacked (RF + XGB) Tuned	0.53	0.39	0.52
ğŸ”¥ Best Model:

Stacked (Random Forest + XGBoost) with Tuned Meta-Learner

Highest recall (0.53)

Balanced F1 (0.39)

Outperformed individual classical models

ğŸ§  Key Insights
1ï¸âƒ£ Linear models performed strongly

Well-regularized logistic regression achieved high recall due to explicit class weighting.

2ï¸âƒ£ Complexity â‰  Performance

Many ensemble boosting models underperformed due to:

Majority class bias

Accuracy-focused tuning

Limited hyperparameter exploration

3ï¸âƒ£ Neural Network Failure

MLP collapsed to predicting majority class (Recall = 0.01).

4ï¸âƒ£ TabPFN Competitiveness

Achieved recall 0.46 without dataset-specific tuning.
Demonstrates promise of foundation models in tabular healthcare prediction.

5ï¸âƒ£ Stacked Ensembles Require Proper Optimization

Untuned stacked models collapsed.
After recall-optimized GridSearch, performance significantly improved.

ğŸ” Most Predictive Features

Logistic regression analysis identified:

Low Self-Esteem (Strongest predictor)

Poor Family Communication

High Screen Time Before Bed

Daily Phone Usage

These provide actionable insights for prevention strategies.

ğŸ¥ Clinical Implications

53% sensitivity can meaningfully improve early screening

Suitable for two-stage mental health screening frameworks

Threshold tuning allows recall-precision tradeoff depending on deployment context

âš ï¸ This is a screening tool â€” not a diagnostic system.

ğŸš§ Limitations

Cross-sectional dataset

Self-reported survey bias

No external validation

Limited sample size for deep models

No probability calibration analysis

Future work includes:

Longitudinal modeling

SHAP interpretability

Alternative sampling methods (ADASYN, SMOTEENN)

External dataset validation

Integration with clinicians

ğŸ›  Technologies Used

Python

Scikit-learn

XGBoost

LightGBM

CatBoost

PyTorch

TabPFN

SMOTE (imbalanced-learn)

GridSearchCV

ğŸ“Œ Conclusion

This study demonstrates that:

Properly tuned stacked ensembles can improve minority class sensitivity

Foundation models like TabPFN are viable alternatives in small tabular datasets

Metric selection (recall-focused) significantly impacts model selection

Model tuning strategy matters more than algorithm complexity

The ultimate objective is to support early identification and timely intervention for at-risk adolescents.
